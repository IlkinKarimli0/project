{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d271a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from nmt_utils import *\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e4940dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10323, 34)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('datasets/dataset','rb') as fb:\n",
    "    dataset = pickle.load(fb)\n",
    "    \n",
    "with open('vocabs/human_vocab','rb') as fb:\n",
    "    human_vocab = pickle.load(fb)\n",
    "\n",
    "with open('vocabs/machine_vocab','rb') as fb:\n",
    "    machine_vocab = pickle.load(fb)\n",
    "\n",
    "with open('vocabs/inv_machine_vocab','rb') as fb:\n",
    "    inv_machine_vocab = pickle.load(fb)\n",
    "\n",
    "\n",
    "m = len(dataset)\n",
    "random.shuffle(dataset)\n",
    "\n",
    "# 0.3% test set\n",
    "train = dataset[:-(m//300)]\n",
    "test = dataset[-(m//300):]\n",
    "\n",
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca30e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, ',': 1, '.': 2, '/': 3, '0': 4, '1': 5, '2': 6, '3': 7, '4': 8, '5': 9, '6': 10, '7': 11, '8': 12, '9': 13, 'a': 14, 'b': 15, 'c': 16, 'd': 17, 'e': 18, 'f': 19, 'i': 20, 'k': 21, 'l': 22, 'm': 23, 'n': 24, 'o': 25, 'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'x': 33, 'y': 34, 'z': 35, 'ç': 36, 'ü': 37, 'ı': 38, 'ş': 39, 'ə': 40, '<unk>': 41, '<pad>': 42}\n"
     ]
    }
   ],
   "source": [
    "print(human_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f05d76fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10357, 30)\n",
      "Y.shape: (10357, 10)\n",
      "Xoh.shape: (10357, 30, 43)\n",
      "Yoh.shape: (10357, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "#maximum length for input and output dates, in order to make all input data in the same length\n",
    "Tx = 30\n",
    "Ty = 10  # xxxx-xx-xx output will be in this format so all outputs will be in 10 character long\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "# Each character has its index X and Y we represent data as a list of indices. Then, we change each indices to \n",
    "# one hot encoding vector in depth axis \n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcc6d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x : Tensor.\n",
    "        axis: Integer, axis along which the softmax normalization is applied.\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation.\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bca5cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_human_vocab = len(list(human_vocab.keys()))\n",
    "len_machine_vocab = len(list(machine_vocab.keys()))\n",
    "\n",
    "n_s = 64 # number of units for the post-attention LSTM's hidden state \"s\"\n",
    "n_a = 32 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3897211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "class neural_translation_model(layers.Layer):\n",
    "    \n",
    "    def __init__(self, Tx = 30, Ty = 10, n_a = 32, n_s = 64, human_vocab_size = len_human_vocab\n",
    "                                                           , machine_vocab_size = len_machine_vocab):\n",
    "        \n",
    "        # Default parameter for model\n",
    "        self.Tx = Tx\n",
    "        self.Ty = Ty        \n",
    "        self.n_a = n_a # number of units for the pre-attention, bi-directional LSTM's hidden state 'a' \n",
    "        self.n_s = n_s # number of units for the post-attention LSTM's hidden state \"s\"\n",
    "        self.human_vocab_size = human_vocab_size\n",
    "        self.machine_vocab_size = machine_vocab_size\n",
    "        \n",
    "        \n",
    "        \n",
    "        # We will share weights with those layer. In order to prevent them to be intialized for each time step we can either \n",
    "        # define them as a global variable or we can create their object\n",
    "        self.repeator = layers.RepeatVector(Tx)\n",
    "        self.concatenator =  layers.Concatenate(axis=-1)\n",
    "        self.densor1 = layers.Dense(10, activation = \"tanh\")\n",
    "        self.densor2 = layers.Dense(1, activation = \"relu\")\n",
    "        self.activator = layers.Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "        self.dotor = layers.Dot(axes = 1)\n",
    "        \n",
    "        self.post_activation_LSTM_cell = layers.LSTM(n_s, return_state = True) # Please do not modify this global variable.\n",
    "        self.output_layer = layers.Dense(len(machine_vocab), activation=softmax)\n",
    "        \n",
    "    def a_step_attention(self, a, s_prev):\n",
    "        #it is same activation that will be shared for all t_delta activations to calculate alpha\n",
    "        s_prev = self.repeator(s_prev)\n",
    "        #concatenate the activations with hidden state of post attention LSTM \n",
    "        concatenation = self.concatenator([a,s_prev])\n",
    "        \n",
    "        #Here is the small fully connected neural network to find attention weights \n",
    "        # intermediate energies\n",
    "        e = self.densor1(concatenation)\n",
    "        # Energies\n",
    "        energies = self.densor2(e)\n",
    "        #softmax to calculate alphas\n",
    "        alpha = self.activator(energies)\n",
    "        \n",
    "        # context = sum_over_t_x( alpha(t_y,t_x)) * a(t_x)\n",
    "        context = self.dotor([alpha,a])\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    def model(self):\n",
    "        \n",
    "        X  = layers.Input(shape = (self.Tx,self.human_vocab_size))\n",
    "        s0 = layers.Input(shape = (self.n_s,), name ='s0')\n",
    "        c0 = layers.Input(shape = (self.n_s,), name ='c0')\n",
    "        \n",
    "        s = s0 \n",
    "        c = c0 \n",
    "        \n",
    "        a = layers.Bidirectional(layers.LSTM(self.n_a ,return_sequences= True))(X)\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        for t in range(self.Ty):\n",
    "            \n",
    "            context = self.a_step_attention(a, s)\n",
    "            \n",
    "            s, _, c = self.post_activation_LSTM_cell(context,initial_state=[s, c])\n",
    "            \n",
    "            out = self.output_layer(s)\n",
    "            \n",
    "            outputs.append(out)\n",
    "            \n",
    "        model = tf.keras.Model(inputs = [X,s0,c0] , outputs = outputs)\n",
    "        \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1faea1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model = neural_translation_model().model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41a1e5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 30, 43)]     0           []                               \n",
      "                                                                                                  \n",
      " s0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 30, 64)      19456       ['input_2[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " repeat_vector_1 (RepeatVector)  (None, 30, 64)      0           ['s0[0][0]',                     \n",
      "                                                                  'lstm_2[0][0]',                 \n",
      "                                                                  'lstm_2[1][0]',                 \n",
      "                                                                  'lstm_2[2][0]',                 \n",
      "                                                                  'lstm_2[3][0]',                 \n",
      "                                                                  'lstm_2[4][0]',                 \n",
      "                                                                  'lstm_2[5][0]',                 \n",
      "                                                                  'lstm_2[6][0]',                 \n",
      "                                                                  'lstm_2[7][0]',                 \n",
      "                                                                  'lstm_2[8][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 30, 128)      0           ['bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[0][0]',        \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[1][0]',        \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[2][0]',        \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[3][0]',        \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[4][0]',        \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[5][0]',        \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[6][0]',        \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[7][0]',        \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[8][0]',        \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'repeat_vector_1[9][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 30, 10)       1290        ['concatenate_1[0][0]',          \n",
      "                                                                  'concatenate_1[1][0]',          \n",
      "                                                                  'concatenate_1[2][0]',          \n",
      "                                                                  'concatenate_1[3][0]',          \n",
      "                                                                  'concatenate_1[4][0]',          \n",
      "                                                                  'concatenate_1[5][0]',          \n",
      "                                                                  'concatenate_1[6][0]',          \n",
      "                                                                  'concatenate_1[7][0]',          \n",
      "                                                                  'concatenate_1[8][0]',          \n",
      "                                                                  'concatenate_1[9][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 30, 1)        11          ['dense_3[0][0]',                \n",
      "                                                                  'dense_3[1][0]',                \n",
      "                                                                  'dense_3[2][0]',                \n",
      "                                                                  'dense_3[3][0]',                \n",
      "                                                                  'dense_3[4][0]',                \n",
      "                                                                  'dense_3[5][0]',                \n",
      "                                                                  'dense_3[6][0]',                \n",
      "                                                                  'dense_3[7][0]',                \n",
      "                                                                  'dense_3[8][0]',                \n",
      "                                                                  'dense_3[9][0]']                \n",
      "                                                                                                  \n",
      " attention_weights (Activation)  (None, 30, 1)       0           ['dense_4[0][0]',                \n",
      "                                                                  'dense_4[1][0]',                \n",
      "                                                                  'dense_4[2][0]',                \n",
      "                                                                  'dense_4[3][0]',                \n",
      "                                                                  'dense_4[4][0]',                \n",
      "                                                                  'dense_4[5][0]',                \n",
      "                                                                  'dense_4[6][0]',                \n",
      "                                                                  'dense_4[7][0]',                \n",
      "                                                                  'dense_4[8][0]',                \n",
      "                                                                  'dense_4[9][0]']                \n",
      "                                                                                                  \n",
      " dot_1 (Dot)                    (None, 1, 64)        0           ['attention_weights[0][0]',      \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'attention_weights[1][0]',      \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'attention_weights[2][0]',      \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'attention_weights[3][0]',      \n",
      "                                                                  'bidirectional_1[0][0]',        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'attention_weights[4][0]',      \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'attention_weights[5][0]',      \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'attention_weights[6][0]',      \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'attention_weights[7][0]',      \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'attention_weights[8][0]',      \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'attention_weights[9][0]',      \n",
      "                                                                  'bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " c0 (InputLayer)                [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 64),         33024       ['dot_1[0][0]',                  \n",
      "                                 (None, 64),                      's0[0][0]',                     \n",
      "                                 (None, 64)]                      'c0[0][0]',                     \n",
      "                                                                  'dot_1[1][0]',                  \n",
      "                                                                  'lstm_2[0][0]',                 \n",
      "                                                                  'lstm_2[0][2]',                 \n",
      "                                                                  'dot_1[2][0]',                  \n",
      "                                                                  'lstm_2[1][0]',                 \n",
      "                                                                  'lstm_2[1][2]',                 \n",
      "                                                                  'dot_1[3][0]',                  \n",
      "                                                                  'lstm_2[2][0]',                 \n",
      "                                                                  'lstm_2[2][2]',                 \n",
      "                                                                  'dot_1[4][0]',                  \n",
      "                                                                  'lstm_2[3][0]',                 \n",
      "                                                                  'lstm_2[3][2]',                 \n",
      "                                                                  'dot_1[5][0]',                  \n",
      "                                                                  'lstm_2[4][0]',                 \n",
      "                                                                  'lstm_2[4][2]',                 \n",
      "                                                                  'dot_1[6][0]',                  \n",
      "                                                                  'lstm_2[5][0]',                 \n",
      "                                                                  'lstm_2[5][2]',                 \n",
      "                                                                  'dot_1[7][0]',                  \n",
      "                                                                  'lstm_2[6][0]',                 \n",
      "                                                                  'lstm_2[6][2]',                 \n",
      "                                                                  'dot_1[8][0]',                  \n",
      "                                                                  'lstm_2[7][0]',                 \n",
      "                                                                  'lstm_2[7][2]',                 \n",
      "                                                                  'dot_1[9][0]',                  \n",
      "                                                                  'lstm_2[8][0]',                 \n",
      "                                                                  'lstm_2[8][2]']                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 11)           715         ['lstm_2[0][0]',                 \n",
      "                                                                  'lstm_2[1][0]',                 \n",
      "                                                                  'lstm_2[2][0]',                 \n",
      "                                                                  'lstm_2[3][0]',                 \n",
      "                                                                  'lstm_2[4][0]',                 \n",
      "                                                                  'lstm_2[5][0]',                 \n",
      "                                                                  'lstm_2[6][0]',                 \n",
      "                                                                  'lstm_2[7][0]',                 \n",
      "                                                                  'lstm_2[8][0]',                 \n",
      "                                                                  'lstm_2[9][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54,496\n",
      "Trainable params: 54,496\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attention_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea7b1d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate = 0.01,beta_1 = 0.9,beta_2 = 0.999,decay = 0.01) \n",
    "attention_model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d11a4029",
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6b65c169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "648/648 [==============================] - 57s 57ms/step - loss: 8.1927 - dense_5_loss: 0.1972 - dense_5_1_loss: 0.1732 - dense_5_2_loss: 0.9673 - dense_5_3_loss: 1.9011 - dense_5_4_loss: 0.1076 - dense_5_5_loss: 0.3914 - dense_5_6_loss: 1.6577 - dense_5_7_loss: 0.1365 - dense_5_8_loss: 0.9005 - dense_5_9_loss: 1.7603 - dense_5_accuracy: 0.9258 - dense_5_1_accuracy: 0.9522 - dense_5_2_accuracy: 0.6139 - dense_5_3_accuracy: 0.3403 - dense_5_4_accuracy: 0.9848 - dense_5_5_accuracy: 0.8354 - dense_5_6_accuracy: 0.4276 - dense_5_7_accuracy: 0.9737 - dense_5_8_accuracy: 0.6348 - dense_5_9_accuracy: 0.3867\n",
      "Epoch 2/70\n",
      "648/648 [==============================] - 35s 53ms/step - loss: 1.6220 - dense_5_loss: 0.0292 - dense_5_1_loss: 0.0170 - dense_5_2_loss: 0.1843 - dense_5_3_loss: 0.2813 - dense_5_4_loss: 0.0018 - dense_5_5_loss: 0.0660 - dense_5_6_loss: 0.4226 - dense_5_7_loss: 0.0054 - dense_5_8_loss: 0.3790 - dense_5_9_loss: 0.2354 - dense_5_accuracy: 0.9888 - dense_5_1_accuracy: 0.9946 - dense_5_2_accuracy: 0.9590 - dense_5_3_accuracy: 0.9674 - dense_5_4_accuracy: 0.9999 - dense_5_5_accuracy: 0.9799 - dense_5_6_accuracy: 0.8950 - dense_5_7_accuracy: 0.9998 - dense_5_8_accuracy: 0.8805 - dense_5_9_accuracy: 0.9502\n",
      "Epoch 3/70\n",
      "648/648 [==============================] - 34s 52ms/step - loss: 0.6060 - dense_5_loss: 0.0138 - dense_5_1_loss: 0.0080 - dense_5_2_loss: 0.0500 - dense_5_3_loss: 0.0793 - dense_5_4_loss: 7.1461e-04 - dense_5_5_loss: 0.0231 - dense_5_6_loss: 0.1274 - dense_5_7_loss: 0.0021 - dense_5_8_loss: 0.2099 - dense_5_9_loss: 0.0917 - dense_5_accuracy: 0.9964 - dense_5_1_accuracy: 0.9983 - dense_5_2_accuracy: 0.9936 - dense_5_3_accuracy: 0.9948 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9947 - dense_5_6_accuracy: 0.9794 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9342 - dense_5_9_accuracy: 0.9819\n",
      "Epoch 4/70\n",
      "648/648 [==============================] - 21s 33ms/step - loss: 0.3533 - dense_5_loss: 0.0075 - dense_5_1_loss: 0.0038 - dense_5_2_loss: 0.0266 - dense_5_3_loss: 0.0516 - dense_5_4_loss: 4.3012e-04 - dense_5_5_loss: 0.0119 - dense_5_6_loss: 0.0640 - dense_5_7_loss: 0.0015 - dense_5_8_loss: 0.1251 - dense_5_9_loss: 0.0609 - dense_5_accuracy: 0.9986 - dense_5_1_accuracy: 0.9992 - dense_5_2_accuracy: 0.9962 - dense_5_3_accuracy: 0.9957 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9978 - dense_5_6_accuracy: 0.9900 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9643 - dense_5_9_accuracy: 0.9879\n",
      "Epoch 5/70\n",
      "648/648 [==============================] - 21s 32ms/step - loss: 0.2486 - dense_5_loss: 0.0057 - dense_5_1_loss: 0.0032 - dense_5_2_loss: 0.0204 - dense_5_3_loss: 0.0423 - dense_5_4_loss: 2.8819e-04 - dense_5_5_loss: 0.0081 - dense_5_6_loss: 0.0438 - dense_5_7_loss: 0.0014 - dense_5_8_loss: 0.0785 - dense_5_9_loss: 0.0451 - dense_5_accuracy: 0.9990 - dense_5_1_accuracy: 0.9993 - dense_5_2_accuracy: 0.9962 - dense_5_3_accuracy: 0.9959 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9988 - dense_5_6_accuracy: 0.9930 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9815 - dense_5_9_accuracy: 0.9916\n",
      "Epoch 6/70\n",
      "648/648 [==============================] - 22s 33ms/step - loss: 0.1797 - dense_5_loss: 0.0035 - dense_5_1_loss: 0.0018 - dense_5_2_loss: 0.0158 - dense_5_3_loss: 0.0367 - dense_5_4_loss: 1.7982e-04 - dense_5_5_loss: 0.0056 - dense_5_6_loss: 0.0311 - dense_5_7_loss: 0.0012 - dense_5_8_loss: 0.0524 - dense_5_9_loss: 0.0315 - dense_5_accuracy: 0.9996 - dense_5_1_accuracy: 0.9998 - dense_5_2_accuracy: 0.9975 - dense_5_3_accuracy: 0.9959 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9992 - dense_5_6_accuracy: 0.9961 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9893 - dense_5_9_accuracy: 0.9943\n",
      "Epoch 7/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.1446 - dense_5_loss: 0.0032 - dense_5_1_loss: 0.0018 - dense_5_2_loss: 0.0138 - dense_5_3_loss: 0.0339 - dense_5_4_loss: 1.3269e-04 - dense_5_5_loss: 0.0049 - dense_5_6_loss: 0.0247 - dense_5_7_loss: 9.2139e-04 - dense_5_8_loss: 0.0378 - dense_5_9_loss: 0.0235 - dense_5_accuracy: 0.9993 - dense_5_1_accuracy: 0.9998 - dense_5_2_accuracy: 0.9974 - dense_5_3_accuracy: 0.9962 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9993 - dense_5_6_accuracy: 0.9966 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9931 - dense_5_9_accuracy: 0.9969\n",
      "Epoch 8/70\n",
      "648/648 [==============================] - 23s 36ms/step - loss: 0.1166 - dense_5_loss: 0.0027 - dense_5_1_loss: 0.0016 - dense_5_2_loss: 0.0119 - dense_5_3_loss: 0.0317 - dense_5_4_loss: 9.4443e-05 - dense_5_5_loss: 0.0035 - dense_5_6_loss: 0.0179 - dense_5_7_loss: 7.3945e-04 - dense_5_8_loss: 0.0283 - dense_5_9_loss: 0.0181 - dense_5_accuracy: 0.9994 - dense_5_1_accuracy: 0.9998 - dense_5_2_accuracy: 0.9981 - dense_5_3_accuracy: 0.9963 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9996 - dense_5_6_accuracy: 0.9980 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9957 - dense_5_9_accuracy: 0.9976\n",
      "Epoch 9/70\n",
      "648/648 [==============================] - 24s 37ms/step - loss: 0.1002 - dense_5_loss: 0.0022 - dense_5_1_loss: 0.0013 - dense_5_2_loss: 0.0105 - dense_5_3_loss: 0.0292 - dense_5_4_loss: 7.5935e-05 - dense_5_5_loss: 0.0027 - dense_5_6_loss: 0.0149 - dense_5_7_loss: 6.0813e-04 - dense_5_8_loss: 0.0236 - dense_5_9_loss: 0.0152 - dense_5_accuracy: 0.9995 - dense_5_1_accuracy: 0.9998 - dense_5_2_accuracy: 0.9980 - dense_5_3_accuracy: 0.9962 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9997 - dense_5_6_accuracy: 0.9984 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9958 - dense_5_9_accuracy: 0.9983\n",
      "Epoch 10/70\n",
      "648/648 [==============================] - 23s 35ms/step - loss: 0.0870 - dense_5_loss: 0.0017 - dense_5_1_loss: 0.0010 - dense_5_2_loss: 0.0092 - dense_5_3_loss: 0.0276 - dense_5_4_loss: 6.6068e-05 - dense_5_5_loss: 0.0024 - dense_5_6_loss: 0.0123 - dense_5_7_loss: 4.7516e-04 - dense_5_8_loss: 0.0187 - dense_5_9_loss: 0.0134 - dense_5_accuracy: 0.9998 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9985 - dense_5_3_accuracy: 0.9964 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9997 - dense_5_6_accuracy: 0.9986 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9971 - dense_5_9_accuracy: 0.9980\n",
      "Epoch 11/70\n",
      "648/648 [==============================] - 23s 35ms/step - loss: 0.0765 - dense_5_loss: 0.0014 - dense_5_1_loss: 7.6989e-04 - dense_5_2_loss: 0.0081 - dense_5_3_loss: 0.0262 - dense_5_4_loss: 5.8537e-05 - dense_5_5_loss: 0.0022 - dense_5_6_loss: 0.0104 - dense_5_7_loss: 4.0332e-04 - dense_5_8_loss: 0.0155 - dense_5_9_loss: 0.0114 - dense_5_accuracy: 0.9999 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9986 - dense_5_3_accuracy: 0.9963 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9998 - dense_5_6_accuracy: 0.9986 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9972 - dense_5_9_accuracy: 0.9986\n",
      "Epoch 12/70\n",
      "648/648 [==============================] - 24s 37ms/step - loss: 0.0692 - dense_5_loss: 0.0013 - dense_5_1_loss: 7.6228e-04 - dense_5_2_loss: 0.0072 - dense_5_3_loss: 0.0253 - dense_5_4_loss: 4.9006e-05 - dense_5_5_loss: 0.0019 - dense_5_6_loss: 0.0089 - dense_5_7_loss: 3.6838e-04 - dense_5_8_loss: 0.0131 - dense_5_9_loss: 0.0105 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9987 - dense_5_3_accuracy: 0.9964 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9998 - dense_5_6_accuracy: 0.9989 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9986 - dense_5_9_accuracy: 0.9986\n",
      "Epoch 13/70\n",
      "648/648 [==============================] - 23s 36ms/step - loss: 0.0627 - dense_5_loss: 0.0011 - dense_5_1_loss: 6.1696e-04 - dense_5_2_loss: 0.0067 - dense_5_3_loss: 0.0242 - dense_5_4_loss: 4.1211e-05 - dense_5_5_loss: 0.0017 - dense_5_6_loss: 0.0074 - dense_5_7_loss: 2.7896e-04 - dense_5_8_loss: 0.0110 - dense_5_9_loss: 0.0096 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9987 - dense_5_3_accuracy: 0.9965 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9994 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9984 - dense_5_9_accuracy: 0.9986\n",
      "Epoch 14/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 22s 33ms/step - loss: 0.0574 - dense_5_loss: 9.6447e-04 - dense_5_1_loss: 5.3968e-04 - dense_5_2_loss: 0.0061 - dense_5_3_loss: 0.0233 - dense_5_4_loss: 3.7409e-05 - dense_5_5_loss: 0.0014 - dense_5_6_loss: 0.0066 - dense_5_7_loss: 2.4468e-04 - dense_5_8_loss: 0.0095 - dense_5_9_loss: 0.0087 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9989 - dense_5_3_accuracy: 0.9967 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9993 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9985 - dense_5_9_accuracy: 0.9988\n",
      "Epoch 15/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.0538 - dense_5_loss: 9.6013e-04 - dense_5_1_loss: 5.2808e-04 - dense_5_2_loss: 0.0058 - dense_5_3_loss: 0.0226 - dense_5_4_loss: 3.4906e-05 - dense_5_5_loss: 0.0014 - dense_5_6_loss: 0.0058 - dense_5_7_loss: 2.1823e-04 - dense_5_8_loss: 0.0085 - dense_5_9_loss: 0.0080 - dense_5_accuracy: 0.9999 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9989 - dense_5_3_accuracy: 0.9965 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9998 - dense_5_6_accuracy: 0.9994 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9986 - dense_5_9_accuracy: 0.9986\n",
      "Epoch 16/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.0511 - dense_5_loss: 8.6244e-04 - dense_5_1_loss: 4.7881e-04 - dense_5_2_loss: 0.0054 - dense_5_3_loss: 0.0228 - dense_5_4_loss: 2.9927e-05 - dense_5_5_loss: 0.0012 - dense_5_6_loss: 0.0055 - dense_5_7_loss: 1.7957e-04 - dense_5_8_loss: 0.0072 - dense_5_9_loss: 0.0075 - dense_5_accuracy: 0.9999 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9991 - dense_5_3_accuracy: 0.9964 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9993 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9989 - dense_5_9_accuracy: 0.9988\n",
      "Epoch 17/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.0476 - dense_5_loss: 7.5393e-04 - dense_5_1_loss: 4.3249e-04 - dense_5_2_loss: 0.0050 - dense_5_3_loss: 0.0218 - dense_5_4_loss: 2.8962e-05 - dense_5_5_loss: 0.0011 - dense_5_6_loss: 0.0048 - dense_5_7_loss: 1.7928e-04 - dense_5_8_loss: 0.0066 - dense_5_9_loss: 0.0069 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9992 - dense_5_3_accuracy: 0.9965 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9996 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9990 - dense_5_9_accuracy: 0.9989\n",
      "Epoch 18/70\n",
      "648/648 [==============================] - 23s 35ms/step - loss: 0.0450 - dense_5_loss: 7.1332e-04 - dense_5_1_loss: 3.8180e-04 - dense_5_2_loss: 0.0048 - dense_5_3_loss: 0.0212 - dense_5_4_loss: 2.5247e-05 - dense_5_5_loss: 0.0011 - dense_5_6_loss: 0.0042 - dense_5_7_loss: 1.6217e-04 - dense_5_8_loss: 0.0057 - dense_5_9_loss: 0.0067 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9992 - dense_5_3_accuracy: 0.9968 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9996 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9992 - dense_5_9_accuracy: 0.9989\n",
      "Epoch 19/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.0427 - dense_5_loss: 6.4465e-04 - dense_5_1_loss: 3.7455e-04 - dense_5_2_loss: 0.0045 - dense_5_3_loss: 0.0209 - dense_5_4_loss: 2.5748e-05 - dense_5_5_loss: 9.0084e-04 - dense_5_6_loss: 0.0039 - dense_5_7_loss: 1.4316e-04 - dense_5_8_loss: 0.0051 - dense_5_9_loss: 0.0060 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9993 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9996 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9993 - dense_5_9_accuracy: 0.9989\n",
      "Epoch 20/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.0412 - dense_5_loss: 6.0546e-04 - dense_5_1_loss: 3.4381e-04 - dense_5_2_loss: 0.0044 - dense_5_3_loss: 0.0204 - dense_5_4_loss: 2.3959e-05 - dense_5_5_loss: 8.5713e-04 - dense_5_6_loss: 0.0037 - dense_5_7_loss: 1.2624e-04 - dense_5_8_loss: 0.0050 - dense_5_9_loss: 0.0059 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9992 - dense_5_3_accuracy: 0.9968 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9998 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9993 - dense_5_9_accuracy: 0.9989\n",
      "Epoch 21/70\n",
      "648/648 [==============================] - 22s 35ms/step - loss: 0.0390 - dense_5_loss: 5.4008e-04 - dense_5_1_loss: 3.0326e-04 - dense_5_2_loss: 0.0040 - dense_5_3_loss: 0.0200 - dense_5_4_loss: 2.2046e-05 - dense_5_5_loss: 7.3049e-04 - dense_5_6_loss: 0.0034 - dense_5_7_loss: 1.2406e-04 - dense_5_8_loss: 0.0042 - dense_5_9_loss: 0.0057 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9993 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9998 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9993 - dense_5_9_accuracy: 0.9992\n",
      "Epoch 22/70\n",
      "648/648 [==============================] - 22s 35ms/step - loss: 0.0376 - dense_5_loss: 5.0606e-04 - dense_5_1_loss: 2.9473e-04 - dense_5_2_loss: 0.0040 - dense_5_3_loss: 0.0196 - dense_5_4_loss: 2.1072e-05 - dense_5_5_loss: 6.6908e-04 - dense_5_6_loss: 0.0031 - dense_5_7_loss: 1.0904e-04 - dense_5_8_loss: 0.0039 - dense_5_9_loss: 0.0054 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9992 - dense_5_3_accuracy: 0.9967 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9998 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9997 - dense_5_9_accuracy: 0.9990\n",
      "Epoch 23/70\n",
      "648/648 [==============================] - 23s 35ms/step - loss: 0.0363 - dense_5_loss: 4.6425e-04 - dense_5_1_loss: 2.8743e-04 - dense_5_2_loss: 0.0036 - dense_5_3_loss: 0.0194 - dense_5_4_loss: 1.8982e-05 - dense_5_5_loss: 6.1925e-04 - dense_5_6_loss: 0.0030 - dense_5_7_loss: 9.7678e-05 - dense_5_8_loss: 0.0037 - dense_5_9_loss: 0.0052 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9993 - dense_5_3_accuracy: 0.9968 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9998 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9995 - dense_5_9_accuracy: 0.9992\n",
      "Epoch 24/70\n",
      "648/648 [==============================] - 22s 35ms/step - loss: 0.0351 - dense_5_loss: 4.4378e-04 - dense_5_1_loss: 2.8043e-04 - dense_5_2_loss: 0.0035 - dense_5_3_loss: 0.0190 - dense_5_4_loss: 1.7969e-05 - dense_5_5_loss: 6.0077e-04 - dense_5_6_loss: 0.0028 - dense_5_7_loss: 9.6000e-05 - dense_5_8_loss: 0.0034 - dense_5_9_loss: 0.0049 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9993 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9997 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9997 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 25/70\n",
      "648/648 [==============================] - 22s 35ms/step - loss: 0.0341 - dense_5_loss: 4.2461e-04 - dense_5_1_loss: 2.5780e-04 - dense_5_2_loss: 0.0033 - dense_5_3_loss: 0.0190 - dense_5_4_loss: 1.7223e-05 - dense_5_5_loss: 5.5383e-04 - dense_5_6_loss: 0.0025 - dense_5_7_loss: 8.5887e-05 - dense_5_8_loss: 0.0031 - dense_5_9_loss: 0.0048 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9992 - dense_5_3_accuracy: 0.9968 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9998 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9997 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 26/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 22s 33ms/step - loss: 0.0329 - dense_5_loss: 4.1594e-04 - dense_5_1_loss: 2.5535e-04 - dense_5_2_loss: 0.0032 - dense_5_3_loss: 0.0184 - dense_5_4_loss: 1.6483e-05 - dense_5_5_loss: 5.1098e-04 - dense_5_6_loss: 0.0025 - dense_5_7_loss: 8.4468e-05 - dense_5_8_loss: 0.0030 - dense_5_9_loss: 0.0045 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9994 - dense_5_3_accuracy: 0.9967 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 0.9998 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9998 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 27/70\n",
      "648/648 [==============================] - 22s 33ms/step - loss: 0.0319 - dense_5_loss: 3.8360e-04 - dense_5_1_loss: 2.4560e-04 - dense_5_2_loss: 0.0030 - dense_5_3_loss: 0.0181 - dense_5_4_loss: 1.5154e-05 - dense_5_5_loss: 4.8732e-04 - dense_5_6_loss: 0.0024 - dense_5_7_loss: 7.7091e-05 - dense_5_8_loss: 0.0028 - dense_5_9_loss: 0.0044 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9967 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 0.9999 - dense_5_6_accuracy: 0.9999 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9998 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 28/70\n",
      "648/648 [==============================] - 22s 33ms/step - loss: 0.0309 - dense_5_loss: 3.7916e-04 - dense_5_1_loss: 2.3890e-04 - dense_5_2_loss: 0.0029 - dense_5_3_loss: 0.0179 - dense_5_4_loss: 1.5712e-05 - dense_5_5_loss: 4.6412e-04 - dense_5_6_loss: 0.0022 - dense_5_7_loss: 7.4784e-05 - dense_5_8_loss: 0.0026 - dense_5_9_loss: 0.0042 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9995 - dense_5_3_accuracy: 0.9968 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9998 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 29/70\n",
      "648/648 [==============================] - 22s 33ms/step - loss: 0.0302 - dense_5_loss: 3.4723e-04 - dense_5_1_loss: 2.2672e-04 - dense_5_2_loss: 0.0028 - dense_5_3_loss: 0.0177 - dense_5_4_loss: 1.4424e-05 - dense_5_5_loss: 4.2881e-04 - dense_5_6_loss: 0.0021 - dense_5_7_loss: 6.9441e-05 - dense_5_8_loss: 0.0024 - dense_5_9_loss: 0.0040 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9995 - dense_5_3_accuracy: 0.9968 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9999 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 30/70\n",
      "648/648 [==============================] - 22s 33ms/step - loss: 0.0295 - dense_5_loss: 3.6103e-04 - dense_5_1_loss: 2.3146e-04 - dense_5_2_loss: 0.0027 - dense_5_3_loss: 0.0173 - dense_5_4_loss: 1.4564e-05 - dense_5_5_loss: 4.4477e-04 - dense_5_6_loss: 0.0020 - dense_5_7_loss: 6.5572e-05 - dense_5_8_loss: 0.0024 - dense_5_9_loss: 0.0039 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9994 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 0.9999 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9998 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 31/70\n",
      "648/648 [==============================] - 22s 33ms/step - loss: 0.0289 - dense_5_loss: 3.3481e-04 - dense_5_1_loss: 2.1753e-04 - dense_5_2_loss: 0.0025 - dense_5_3_loss: 0.0174 - dense_5_4_loss: 1.3132e-05 - dense_5_5_loss: 3.9500e-04 - dense_5_6_loss: 0.0019 - dense_5_7_loss: 6.1439e-05 - dense_5_8_loss: 0.0022 - dense_5_9_loss: 0.0038 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9995 - dense_5_3_accuracy: 0.9968 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9999 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 32/70\n",
      "648/648 [==============================] - 22s 33ms/step - loss: 0.0281 - dense_5_loss: 3.2752e-04 - dense_5_1_loss: 2.0639e-04 - dense_5_2_loss: 0.0025 - dense_5_3_loss: 0.0170 - dense_5_4_loss: 1.2582e-05 - dense_5_5_loss: 3.9559e-04 - dense_5_6_loss: 0.0018 - dense_5_7_loss: 5.9853e-05 - dense_5_8_loss: 0.0021 - dense_5_9_loss: 0.0037 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9968 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9998 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 33/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.0276 - dense_5_loss: 3.0176e-04 - dense_5_1_loss: 2.0171e-04 - dense_5_2_loss: 0.0024 - dense_5_3_loss: 0.0170 - dense_5_4_loss: 1.2431e-05 - dense_5_5_loss: 3.7168e-04 - dense_5_6_loss: 0.0018 - dense_5_7_loss: 5.9000e-05 - dense_5_8_loss: 0.0020 - dense_5_9_loss: 0.0035 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9995 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9998 - dense_5_9_accuracy: 0.9994\n",
      "Epoch 34/70\n",
      "648/648 [==============================] - 22s 33ms/step - loss: 0.0269 - dense_5_loss: 2.9817e-04 - dense_5_1_loss: 1.9976e-04 - dense_5_2_loss: 0.0023 - dense_5_3_loss: 0.0167 - dense_5_4_loss: 1.2940e-05 - dense_5_5_loss: 3.6634e-04 - dense_5_6_loss: 0.0017 - dense_5_7_loss: 5.5451e-05 - dense_5_8_loss: 0.0019 - dense_5_9_loss: 0.0034 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9998 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 35/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.0262 - dense_5_loss: 2.9518e-04 - dense_5_1_loss: 1.8809e-04 - dense_5_2_loss: 0.0022 - dense_5_3_loss: 0.0164 - dense_5_4_loss: 1.1459e-05 - dense_5_5_loss: 3.4842e-04 - dense_5_6_loss: 0.0016 - dense_5_7_loss: 5.1754e-05 - dense_5_8_loss: 0.0019 - dense_5_9_loss: 0.0032 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9967 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9999 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 36/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.0259 - dense_5_loss: 2.7866e-04 - dense_5_1_loss: 1.8774e-04 - dense_5_2_loss: 0.0022 - dense_5_3_loss: 0.0162 - dense_5_4_loss: 1.1260e-05 - dense_5_5_loss: 3.4628e-04 - dense_5_6_loss: 0.0016 - dense_5_7_loss: 5.6177e-05 - dense_5_8_loss: 0.0017 - dense_5_9_loss: 0.0032 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9999 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 37/70\n",
      "648/648 [==============================] - 22s 34ms/step - loss: 0.0252 - dense_5_loss: 2.7938e-04 - dense_5_1_loss: 1.9470e-04 - dense_5_2_loss: 0.0020 - dense_5_3_loss: 0.0160 - dense_5_4_loss: 1.1505e-05 - dense_5_5_loss: 3.3825e-04 - dense_5_6_loss: 0.0015 - dense_5_7_loss: 5.5467e-05 - dense_5_8_loss: 0.0017 - dense_5_9_loss: 0.0030 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9970 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9999 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 38/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 23s 35ms/step - loss: 0.0248 - dense_5_loss: 2.7355e-04 - dense_5_1_loss: 1.8183e-04 - dense_5_2_loss: 0.0020 - dense_5_3_loss: 0.0160 - dense_5_4_loss: 1.0133e-05 - dense_5_5_loss: 3.0210e-04 - dense_5_6_loss: 0.0015 - dense_5_7_loss: 5.2112e-05 - dense_5_8_loss: 0.0016 - dense_5_9_loss: 0.0030 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9995 - dense_5_3_accuracy: 0.9971 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9999 - dense_5_9_accuracy: 0.9993\n",
      "Epoch 39/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0245 - dense_5_loss: 2.6858e-04 - dense_5_1_loss: 1.7768e-04 - dense_5_2_loss: 0.0020 - dense_5_3_loss: 0.0158 - dense_5_4_loss: 1.0235e-05 - dense_5_5_loss: 3.2489e-04 - dense_5_6_loss: 0.0014 - dense_5_7_loss: 4.5499e-05 - dense_5_8_loss: 0.0016 - dense_5_9_loss: 0.0029 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9995 - dense_5_3_accuracy: 0.9970 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9999 - dense_5_9_accuracy: 0.9994\n",
      "Epoch 40/70\n",
      "648/648 [==============================] - 20s 30ms/step - loss: 0.0242 - dense_5_loss: 2.4955e-04 - dense_5_1_loss: 1.6841e-04 - dense_5_2_loss: 0.0020 - dense_5_3_loss: 0.0158 - dense_5_4_loss: 1.0050e-05 - dense_5_5_loss: 2.8958e-04 - dense_5_6_loss: 0.0014 - dense_5_7_loss: 4.7994e-05 - dense_5_8_loss: 0.0015 - dense_5_9_loss: 0.0027 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9995\n",
      "Epoch 41/70\n",
      "648/648 [==============================] - 20s 30ms/step - loss: 0.0237 - dense_5_loss: 2.5693e-04 - dense_5_1_loss: 1.7318e-04 - dense_5_2_loss: 0.0019 - dense_5_3_loss: 0.0155 - dense_5_4_loss: 9.8207e-06 - dense_5_5_loss: 2.8121e-04 - dense_5_6_loss: 0.0014 - dense_5_7_loss: 4.3961e-05 - dense_5_8_loss: 0.0014 - dense_5_9_loss: 0.0027 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9994\n",
      "Epoch 42/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0235 - dense_5_loss: 2.4616e-04 - dense_5_1_loss: 1.6685e-04 - dense_5_2_loss: 0.0019 - dense_5_3_loss: 0.0155 - dense_5_4_loss: 9.3050e-06 - dense_5_5_loss: 2.8204e-04 - dense_5_6_loss: 0.0013 - dense_5_7_loss: 4.3191e-05 - dense_5_8_loss: 0.0014 - dense_5_9_loss: 0.0026 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9969 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 0.9999 - dense_5_9_accuracy: 0.9994\n",
      "Epoch 43/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0229 - dense_5_loss: 2.4287e-04 - dense_5_1_loss: 1.6465e-04 - dense_5_2_loss: 0.0017 - dense_5_3_loss: 0.0154 - dense_5_4_loss: 9.1373e-06 - dense_5_5_loss: 2.8211e-04 - dense_5_6_loss: 0.0012 - dense_5_7_loss: 4.3605e-05 - dense_5_8_loss: 0.0013 - dense_5_9_loss: 0.0025 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9971 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9995\n",
      "Epoch 44/70\n",
      "648/648 [==============================] - 20s 30ms/step - loss: 0.0227 - dense_5_loss: 2.4263e-04 - dense_5_1_loss: 1.6202e-04 - dense_5_2_loss: 0.0018 - dense_5_3_loss: 0.0151 - dense_5_4_loss: 9.5636e-06 - dense_5_5_loss: 2.6823e-04 - dense_5_6_loss: 0.0012 - dense_5_7_loss: 4.1853e-05 - dense_5_8_loss: 0.0013 - dense_5_9_loss: 0.0025 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9970 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9995\n",
      "Epoch 45/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0223 - dense_5_loss: 2.2810e-04 - dense_5_1_loss: 1.6089e-04 - dense_5_2_loss: 0.0017 - dense_5_3_loss: 0.0150 - dense_5_4_loss: 9.0657e-06 - dense_5_5_loss: 2.5963e-04 - dense_5_6_loss: 0.0012 - dense_5_7_loss: 4.1613e-05 - dense_5_8_loss: 0.0013 - dense_5_9_loss: 0.0024 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9973 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9995\n",
      "Epoch 46/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0219 - dense_5_loss: 2.1642e-04 - dense_5_1_loss: 1.5063e-04 - dense_5_2_loss: 0.0016 - dense_5_3_loss: 0.0150 - dense_5_4_loss: 9.0801e-06 - dense_5_5_loss: 2.5735e-04 - dense_5_6_loss: 0.0012 - dense_5_7_loss: 3.9109e-05 - dense_5_8_loss: 0.0012 - dense_5_9_loss: 0.0023 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9970 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9996\n",
      "Epoch 47/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0215 - dense_5_loss: 2.3832e-04 - dense_5_1_loss: 1.5505e-04 - dense_5_2_loss: 0.0015 - dense_5_3_loss: 0.0147 - dense_5_4_loss: 9.4454e-06 - dense_5_5_loss: 2.4669e-04 - dense_5_6_loss: 0.0011 - dense_5_7_loss: 3.9167e-05 - dense_5_8_loss: 0.0012 - dense_5_9_loss: 0.0022 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9997 - dense_5_3_accuracy: 0.9973 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9996\n",
      "Epoch 48/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0215 - dense_5_loss: 2.1789e-04 - dense_5_1_loss: 1.5485e-04 - dense_5_2_loss: 0.0016 - dense_5_3_loss: 0.0147 - dense_5_4_loss: 8.6587e-06 - dense_5_5_loss: 2.4595e-04 - dense_5_6_loss: 0.0011 - dense_5_7_loss: 4.0946e-05 - dense_5_8_loss: 0.0012 - dense_5_9_loss: 0.0022 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9971 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9995\n",
      "Epoch 49/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0210 - dense_5_loss: 2.1158e-04 - dense_5_1_loss: 1.5055e-04 - dense_5_2_loss: 0.0015 - dense_5_3_loss: 0.0145 - dense_5_4_loss: 7.9659e-06 - dense_5_5_loss: 2.4083e-04 - dense_5_6_loss: 0.0011 - dense_5_7_loss: 4.0111e-05 - dense_5_8_loss: 0.0012 - dense_5_9_loss: 0.0021 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9972 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9996\n",
      "Epoch 50/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0208 - dense_5_loss: 2.1162e-04 - dense_5_1_loss: 1.4498e-04 - dense_5_2_loss: 0.0015 - dense_5_3_loss: 0.0145 - dense_5_4_loss: 8.9086e-06 - dense_5_5_loss: 2.3463e-04 - dense_5_6_loss: 0.0011 - dense_5_7_loss: 3.6400e-05 - dense_5_8_loss: 0.0011 - dense_5_9_loss: 0.0021 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9972 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9996\n",
      "Epoch 51/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0206 - dense_5_loss: 2.1036e-04 - dense_5_1_loss: 1.4251e-04 - dense_5_2_loss: 0.0015 - dense_5_3_loss: 0.0143 - dense_5_4_loss: 8.4842e-06 - dense_5_5_loss: 2.2991e-04 - dense_5_6_loss: 0.0010 - dense_5_7_loss: 3.5864e-05 - dense_5_8_loss: 0.0011 - dense_5_9_loss: 0.0020 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9973 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9996\n",
      "Epoch 52/70\n",
      "648/648 [==============================] - 20s 31ms/step - loss: 0.0202 - dense_5_loss: 2.1415e-04 - dense_5_1_loss: 1.4395e-04 - dense_5_2_loss: 0.0015 - dense_5_3_loss: 0.0141 - dense_5_4_loss: 8.2951e-06 - dense_5_5_loss: 2.2942e-04 - dense_5_6_loss: 0.0010 - dense_5_7_loss: 3.8508e-05 - dense_5_8_loss: 0.0010 - dense_5_9_loss: 0.0019 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9973 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9997\n",
      "Epoch 53/70\n",
      "648/648 [==============================] - 20s 31ms/step - loss: 0.0200 - dense_5_loss: 2.0347e-04 - dense_5_1_loss: 1.4180e-04 - dense_5_2_loss: 0.0014 - dense_5_3_loss: 0.0141 - dense_5_4_loss: 7.9655e-06 - dense_5_5_loss: 2.1699e-04 - dense_5_6_loss: 0.0010 - dense_5_7_loss: 3.4769e-05 - dense_5_8_loss: 0.0010 - dense_5_9_loss: 0.0019 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9973 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9997\n",
      "Epoch 54/70\n",
      "648/648 [==============================] - 19s 30ms/step - loss: 0.0198 - dense_5_loss: 2.0380e-04 - dense_5_1_loss: 1.3921e-04 - dense_5_2_loss: 0.0014 - dense_5_3_loss: 0.0141 - dense_5_4_loss: 7.5700e-06 - dense_5_5_loss: 2.1481e-04 - dense_5_6_loss: 9.7379e-04 - dense_5_7_loss: 3.5337e-05 - dense_5_8_loss: 0.0010 - dense_5_9_loss: 0.0018 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9972 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9997\n",
      "Epoch 55/70\n",
      "648/648 [==============================] - 21s 33ms/step - loss: 0.0195 - dense_5_loss: 1.9142e-04 - dense_5_1_loss: 1.3145e-04 - dense_5_2_loss: 0.0013 - dense_5_3_loss: 0.0139 - dense_5_4_loss: 7.9508e-06 - dense_5_5_loss: 2.1367e-04 - dense_5_6_loss: 9.7269e-04 - dense_5_7_loss: 3.4026e-05 - dense_5_8_loss: 9.9491e-04 - dense_5_9_loss: 0.0018 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9974 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9998\n",
      "Epoch 56/70\n",
      "648/648 [==============================] - 21s 33ms/step - loss: 0.0193 - dense_5_loss: 2.0079e-04 - dense_5_1_loss: 1.3688e-04 - dense_5_2_loss: 0.0013 - dense_5_3_loss: 0.0138 - dense_5_4_loss: 7.3149e-06 - dense_5_5_loss: 2.1525e-04 - dense_5_6_loss: 9.3949e-04 - dense_5_7_loss: 3.4027e-05 - dense_5_8_loss: 9.6079e-04 - dense_5_9_loss: 0.0018 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9997 - dense_5_3_accuracy: 0.9973 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9997\n",
      "Epoch 57/70\n",
      "648/648 [==============================] - 21s 32ms/step - loss: 0.0191 - dense_5_loss: 1.9243e-04 - dense_5_1_loss: 1.3129e-04 - dense_5_2_loss: 0.0013 - dense_5_3_loss: 0.0136 - dense_5_4_loss: 7.7762e-06 - dense_5_5_loss: 2.1225e-04 - dense_5_6_loss: 9.4270e-04 - dense_5_7_loss: 3.4170e-05 - dense_5_8_loss: 9.4158e-04 - dense_5_9_loss: 0.0017 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9996 - dense_5_3_accuracy: 0.9974 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9998\n",
      "Epoch 58/70\n",
      "516/648 [======================>.......] - ETA: 4s - loss: 0.0166 - dense_5_loss: 1.9739e-04 - dense_5_1_loss: 1.2666e-04 - dense_5_2_loss: 0.0014 - dense_5_3_loss: 0.0110 - dense_5_4_loss: 7.4881e-06 - dense_5_5_loss: 1.8375e-04 - dense_5_6_loss: 8.8396e-04 - dense_5_7_loss: 3.1180e-05 - dense_5_8_loss: 9.7071e-04 - dense_5_9_loss: 0.0018 - dense_5_accuracy: 1.0000 - dense_5_1_accuracy: 1.0000 - dense_5_2_accuracy: 0.9995 - dense_5_3_accuracy: 0.9978 - dense_5_4_accuracy: 1.0000 - dense_5_5_accuracy: 1.0000 - dense_5_6_accuracy: 1.0000 - dense_5_7_accuracy: 1.0000 - dense_5_8_accuracy: 1.0000 - dense_5_9_accuracy: 0.9998"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mattention_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mXoh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ProjectX\\projectx\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\ProjectX\\projectx\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Desktop\\ProjectX\\projectx\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\ProjectX\\projectx\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Desktop\\ProjectX\\projectx\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Desktop\\ProjectX\\projectx\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ProjectX\\projectx\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Desktop\\ProjectX\\projectx\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\Desktop\\ProjectX\\projectx\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attention_model.fit([Xoh, s0, c0], outputs, epochs=70, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e732707b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "source: 10 iyun 2025\n",
      "output: 2025-06-10 \n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "source: 21 avqust 2016\n",
      "output: 2016-08-21 \n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "source: 10 iyun 2007\n",
      "output: 2007-06-10 \n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "source: şənbə may 9 2018\n",
      "output: 2018-05-09 \n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "source: mart 3 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "source: 1 mart 2001\n",
      "output: 2001-03-01 \n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "source: aprelin 18 də 98\n",
      "output: 1998-04-18 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['10 iyun 2025', '21 avqust 2016', '10 iyun 2007', 'Şənbə May 9 2018', 'Mart 3 2001', '1 mart 2001','aprelin 18-də 98']\n",
    "s00 = np.zeros((1, n_s))\n",
    "c00 = np.zeros((1, n_s))\n",
    "for example in EXAMPLES:\n",
    "    example = example.lower().replace('-',' ')\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    source = np.swapaxes(source, 0, 1)\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    prediction = attention_model.predict([source, s00, c00])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d8af7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model.save_weights('models/58epochs_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4452d9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fevral 18 2019',\n",
       " '4 oktyabr 1973',\n",
       " '7 iyun 2000',\n",
       " '23.08.94',\n",
       " '17 iyun 2007',\n",
       " '28 iyun 1974 cümə',\n",
       " 'avqustun 17 də 1990',\n",
       " '20 fev 1979',\n",
       " 'mart 15 1998',\n",
       " '18 may 1995 cümə axşamı',\n",
       " '6 may 1991 bazar ertəsi',\n",
       " '17 yanvar 2004 şənbə',\n",
       " '13 yan 2012',\n",
       " '2 mart 2023 cümə axşamı',\n",
       " '13 noy 1999',\n",
       " '17.11.09',\n",
       " '20 oktyabr 2001 şənbə',\n",
       " '28 mart 1973 çərşənbə',\n",
       " '19 iyul 2018',\n",
       " '22 oktyabr 1994',\n",
       " '19 yanvar 2013 şənbə',\n",
       " '9 may 1998',\n",
       " 'oktyabrın 19 da 1972',\n",
       " '21 okt 2005',\n",
       " '17 noyabr 2007 şənbə',\n",
       " '13 avqust 1974 çərşənbə axşamı',\n",
       " '15 iyun 1984',\n",
       " '20 oktyabr 1995 cümə',\n",
       " '29 aprel 1978 şənbə',\n",
       " '13 oktyabr 1977 cümə axşamı',\n",
       " '27 may 2022 cümə',\n",
       " '22 dekabr 2013 bazar',\n",
       " '4 iyun 1979',\n",
       " '9 iyun 1998 çərşənbə axşamı']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = [test_sample[0] for test_sample in test]\n",
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea1c6f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "source: fevral 18 2019\n",
      "output: 2019-02-18 \n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "source: 4 oktyabr 1973\n",
      "output: 1973-10-04 \n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "source: 7 iyun 2000\n",
      "output: 2000-06-07 \n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "source: 23.08.94\n",
      "output: 1994-08-23 \n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "source: 17 iyun 2007\n",
      "output: 2007-06-17 \n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "source: 28 iyun 1974 cümə\n",
      "output: 1974-06-28 \n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "source: avqustun 17 də 1990\n",
      "output: 1990-08-17 \n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "source: 20 fev 1979\n",
      "output: 1979-02-20 \n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "source: mart 15 1998\n",
      "output: 1998-03-15 \n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "source: 18 may 1995 cümə axşamı\n",
      "output: 1995-05-18 \n",
      "\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "source: 6 may 1991 bazar ertəsi\n",
      "output: 1991-05-06 \n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "source: 17 yanvar 2004 şənbə\n",
      "output: 2004-01-17 \n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "source: 13 yan 2012\n",
      "output: 2012-01-13 \n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "source: 2 mart 2023 cümə axşamı\n",
      "output: 2023-03-02 \n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "source: 13 noy 1999\n",
      "output: 1999-11-13 \n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "source: 17.11.09\n",
      "output: 2009-11-17 \n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "source: 20 oktyabr 2001 şənbə\n",
      "output: 2001-10-20 \n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "source: 28 mart 1973 çərşənbə\n",
      "output: 1973-03-28 \n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "source: 19 iyul 2018\n",
      "output: 2018-07-19 \n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "source: 22 oktyabr 1994\n",
      "output: 1994-10-22 \n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "source: 19 yanvar 2013 şənbə\n",
      "output: 2013-01-19 \n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "source: 9 may 1998\n",
      "output: 1998-05-09 \n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "source: oktyabrın 19 da 1972\n",
      "output: 1972-10-19 \n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "source: 21 okt 2005\n",
      "output: 2005-10-21 \n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "source: 17 noyabr 2007 şənbə\n",
      "output: 2007-11-17 \n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "source: 13 avqust 1974 çərşənbə axşamı\n",
      "output: 1974-08-13 \n",
      "\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "source: 15 iyun 1984\n",
      "output: 1984-06-15 \n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "source: 20 oktyabr 1995 cümə\n",
      "output: 1995-10-20 \n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "source: 29 aprel 1978 şənbə\n",
      "output: 1978-04-29 \n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "source: 13 oktyabr 1977 cümə axşamı\n",
      "output: 1977-10-13 \n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "source: 27 may 2022 cümə\n",
      "output: 2022-05-27 \n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "source: 22 dekabr 2013 bazar\n",
      "output: 2013-12-22 \n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "source: 4 iyun 1979\n",
      "output: 1979-06-04 \n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "source: 9 iyun 1998 çərşənbə axşamı\n",
      "output: 1998-06-09 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in test_list:\n",
    "    example = example.lower().replace('-',' ')\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    source = np.swapaxes(source, 0, 1)\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    prediction = attention_model.predict([source, s00, c00])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89bf8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectx",
   "language": "python",
   "name": "projectx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
